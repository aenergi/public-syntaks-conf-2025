{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# From json dump to parquet with embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from functions.functions_cleancode import remove_soft_hyphens, create_embeddings_in_batches\n",
    "from llm.setup import create_azure_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing JSON files\n",
    "json_dir = '../data/json_files'\n",
    "\n",
    "# List to store cleaned data from all files\n",
    "all_cleaned_data = []\n",
    "\n",
    "# Iterate through all JSON files in the directory\n",
    "for filename in os.listdir(json_dir):\n",
    "    if filename.endswith('.json'):\n",
    "        file_path = os.path.join(json_dir, filename)\n",
    "        \n",
    "        # Load the JSON file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Clean the data\n",
    "        cleaned_data = remove_soft_hyphens(data)\n",
    "        \n",
    "        # Append cleaned data to the list\n",
    "        all_cleaned_data.extend(cleaned_data)\n",
    "\n",
    "# Combine all cleaned data into a single DataFrame\n",
    "df = pd.DataFrame(all_cleaned_data)\n",
    "df = df.drop_duplicates(subset=['id'])\n",
    "print(f'The number of news articles: ' + str(len(df)))\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine 'title' and 'summary' into a new column 'description'\n",
    "df.loc[:, 'description'] = df.apply(\n",
    "    lambda row: row['title'] if pd.isna(row['summary']) else row['title'] + '. ' + row['summary'], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"- \" + df['description'][i])\n",
    "\n",
    "df_description = df[['description']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Embedding the text using AzureOpenAI endpoint, and model **text-embedding-3-large**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = create_azure_client(async_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uncomment if you want to create embeddings again\n",
    "all_embeddings = create_embeddings_in_batches(df=df_description, llm_client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the embeddings to the dataframe\n",
    "df_description['embeddings'] = df_description.index.map(all_embeddings)\n",
    "#save to a parquet file\n",
    "df_description.to_parquet('../data/embeddings/embeddings.parquet', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
